{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda3fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch7ten\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import\n",
    "\n",
    "导入所需要的所有包\n",
    "\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from UV_Encoders import UV_Encoder\n",
    "from UV_Aggregators import UV_Aggregator\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "from texttable import Texttable\n",
    "from param_parsers import parameter_parsers\n",
    "from utils import tab_printer\n",
    "from attentionwalk import AttentionWalkTrainer\n",
    "\n",
    "from metrics import MetronAtK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963c6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NERec模型主体\n",
    "ranking task和rating task的模型主体不同\n",
    "ranking的比较目标是label，计算出预测分数后还需要sigmoid归一化\n",
    "\n",
    "'''\n",
    "\n",
    "class NERec(nn.Module):\n",
    "    \n",
    "    def __init__(self, node_enc, r2e):\n",
    "        super(NERec, self).__init__()    \n",
    "        #和GraphRec不同，由于部分item相连，使得item也有两种邻居，将user和item节点视作一类，后面在模型里对user和item不同的处理则根据uv这个变量进行分类\n",
    "        self.node_enc = node_enc\n",
    "        self.embed_dim = node_enc.embed_dim\n",
    "        #MLP多层感知器\n",
    "        #self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
    "        #self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
    "        #self.w_uv3 = nn.Linear(16, 1)\n",
    "        #self.r2e = r2e\n",
    "        #self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        #self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        #self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        #self.bn4 = nn.BatchNorm1d(16, momentum=0.5)      \n",
    "        #loss函数使用torch.nn自带的损失函数，详细介绍见https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/\n",
    "        #self.criterion = nn.MSELoss()\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, nodes_u, nodes_v):\n",
    "        \n",
    "        #利用uv变量区分user和item节点，False为user节点，True为item节点\n",
    "        embeds_u = self.node_enc(nodes_u, nodes_v, uv = False)\n",
    "        embeds_v = self.node_enc(nodes_v, nodes_u, uv = True)\n",
    "        \n",
    "        #向量点积\n",
    "        scores = torch.mm(embeds_u, embeds_v.t()).diagonal()\n",
    "        scores = torch.sigmoid(scores)\n",
    "        return scores\n",
    "\n",
    "        #MLP多层感知器\n",
    "        #x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
    "        #x_u = F.dropout(x_u, training=self.training)\n",
    "        #x_u = self.w_ur2(x_u)\n",
    "        #x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
    "        #x_v = F.dropout(x_v, training=self.training)\n",
    "        #x_v = self.w_vr2(x_v)\n",
    "\n",
    "        #x_uv = torch.cat((x_u, x_v), 1)\n",
    "        #x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = F.relu(self.bn4(self.w_uv2(x)))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #scores = self.w_uv3(x)\n",
    "\n",
    "    def loss(self, nodes_u, nodes_v, labels_list):\n",
    "        scores = self.forward(nodes_u, nodes_v)\n",
    "        return self.criterion(scores.view(-1), labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d33ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "训练模型以及对验证集和测试集测试计算指标\n",
    "\n",
    "optimizer选择：Adam，学习率初始为0.001，衰减率初始为00001\n",
    "使用方法：\n",
    "torch.optim.Adam(NERec.parameters, lr, weight_decay)\n",
    "torch.optim中文文档：\n",
    "https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-optim/\n",
    "\n",
    "'''\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        batch_nodes_u, batch_nodes_v, ratings_list, labels_list = data\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (\n",
    "                epoch, i, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    return 0\n",
    "\n",
    "def test(model, device, test_loader, _metron):\n",
    "    model.eval()\n",
    "    tmp_pred = []\n",
    "    target = []\n",
    "    user, item, rating, label, c_label = [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for test_u, test_v, tmp_target, tmp_label in test_loader:\n",
    "            #tmp_label就是真实的label\n",
    "            test_u, test_v, tmp_target, tmp_label = test_u.to(device), test_v.to(device), tmp_target.to(device), tmp_label.to(device)\n",
    "            #预测的label，介于0-1之间\n",
    "            val_output = model.forward(test_u, test_v)\n",
    "            \n",
    "            for i in test_u.tolist():\n",
    "                user.append(i)\n",
    "            for i in test_v.tolist():\n",
    "                item.append(i)\n",
    "            for i in tmp_target.tolist():\n",
    "                rating.append(i)\n",
    "            for i in tmp_label.tolist():\n",
    "                label.append(i)\n",
    "            for i in val_output.data.view(-1).tolist():\n",
    "                c_label.append(i)\n",
    "        \n",
    "        _metron.subjects = [user, item, rating, c_label, label]\n",
    "    recall, ndcg = _metron.cal_recall(), _metron.cal_ndcg()\n",
    "    return recall, ndcg\n",
    "            #tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
    "            #真实的label，0或者1\n",
    "            #label.append(list(tmp_label.data.cpu().numpy()))\n",
    "    #tmp_pred = np.array(sum(tmp_pred, []))\n",
    "    #label = np.array(sum(label, []))\n",
    "    #ranking task不同于rating task，评价指标为NDCG命中率，Recall召回率\n",
    "    #expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
    "    #mae = mean_absolute_error(tmp_pred, target)\n",
    "    #return expected_rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493e241",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------------+\n",
      "|      Batch size      |            16             |\n",
      "+======================+===========================+\n",
      "| Beta                 | 0.500                     |\n",
      "+----------------------+---------------------------+\n",
      "| Data                 | ciao_rank1                |\n",
      "+----------------------+---------------------------+\n",
      "| Device               | cuda                      |\n",
      "+----------------------+---------------------------+\n",
      "| Dimensions           | 64                        |\n",
      "+----------------------+---------------------------+\n",
      "| Edge path            | ./input/ciao_edges_16.csv |\n",
      "+----------------------+---------------------------+\n",
      "| Embed dim            | 64                        |\n",
      "+----------------------+---------------------------+\n",
      "| Epochs               | 100                       |\n",
      "+----------------------+---------------------------+\n",
      "| Gamma                | 0.500                     |\n",
      "+----------------------+---------------------------+\n",
      "| Learning rate        | 0.010                     |\n",
      "+----------------------+---------------------------+\n",
      "| Load from checkpoint | 0                         |\n",
      "+----------------------+---------------------------+\n",
      "| Lr                   | 0.001                     |\n",
      "+----------------------+---------------------------+\n",
      "| Mepochs              | 20                        |\n",
      "+----------------------+---------------------------+\n",
      "| Num of walks         | 80                        |\n",
      "+----------------------+---------------------------+\n",
      "| Percent              | 0.200                     |\n",
      "+----------------------+---------------------------+\n",
      "| Test batch size      | 1000                      |\n",
      "+----------------------+---------------------------+\n",
      "| Weight decay         | 0.000                     |\n",
      "+----------------------+---------------------------+\n",
      "| Window size          | 5                         |\n",
      "+----------------------+---------------------------+\n",
      "cuda\n",
      "\n",
      "Target matrix creation started.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adjacency matrix powers: 100%|██████████| 4/4 [00:09<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Social Graph Mmodel.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention Walk (Loss=4.0226): 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get the embedding.\n",
      "\n",
      "[[-0.4503993   0.09798481 -0.4427171  ... -0.43789577 -0.45439765\n",
      "   0.4665582 ]\n",
      " [-0.40613964  0.56851554 -0.37074348 ... -0.3775348  -0.3999195\n",
      "   0.44943348]\n",
      " [-0.4279703   0.54746836 -0.4147276  ... -0.37836653 -0.43439746\n",
      "   0.47709838]\n",
      " ...\n",
      " [ 0.4011242   0.41467637  0.60878277 ...  0.58741915  0.29060107\n",
      "   0.13108891]\n",
      " [ 0.41842166  0.40879625  0.61011505 ...  0.5829974   0.29105255\n",
      "   0.11894531]\n",
      " [ 0.3713764   0.35689595  0.5962181  ...  0.5400495   0.05629883\n",
      "  -0.31438765]]\n",
      "[1,     0] loss: 0.003\n",
      "[1,   100] loss: 0.610\n",
      "[1,   200] loss: 0.553\n",
      "[1,   300] loss: 0.571\n",
      "[1,   400] loss: 0.565\n",
      "[1,   500] loss: 0.558\n",
      "[1,   600] loss: 0.529\n",
      "[1,   700] loss: 0.561\n",
      "[1,   800] loss: 0.508\n",
      "[1,   900] loss: 0.549\n",
      "[1,  1000] loss: 0.543\n",
      "[1,  1100] loss: 0.530\n",
      "[1,  1200] loss: 0.537\n",
      "[1,  1300] loss: 0.545\n",
      "[1,  1400] loss: 0.531\n",
      "[1,  1500] loss: 0.528\n",
      "[1,  1600] loss: 0.525\n",
      "[1,  1700] loss: 0.529\n",
      "[1,  1800] loss: 0.533\n",
      "[1,  1900] loss: 0.535\n",
      "[1,  2000] loss: 0.524\n",
      "[1,  2100] loss: 0.532\n",
      "[1,  2200] loss: 0.537\n",
      "[1,  2300] loss: 0.527\n",
      "[1,  2400] loss: 0.511\n",
      "[1,  2500] loss: 0.513\n",
      "[1,  2600] loss: 0.535\n",
      "[1,  2700] loss: 0.543\n",
      "[1,  2800] loss: 0.542\n",
      "[1,  2900] loss: 0.530\n",
      "[1,  3000] loss: 0.534\n",
      "[1,  3100] loss: 0.508\n",
      "[1,  3200] loss: 0.510\n",
      "[1,  3300] loss: 0.492\n",
      "[1,  3400] loss: 0.519\n",
      "[1,  3500] loss: 0.521\n",
      "[1,  3600] loss: 0.527\n",
      "[1,  3700] loss: 0.530\n",
      "[1,  3800] loss: 0.528\n",
      "[1,  3900] loss: 0.514\n",
      "[1,  4000] loss: 0.516\n",
      "[1,  4100] loss: 0.523\n",
      "[1,  4200] loss: 0.532\n",
      "[1,  4300] loss: 0.487\n",
      "[1,  4400] loss: 0.521\n",
      "[1,  4500] loss: 0.519\n",
      "[1,  4600] loss: 0.497\n",
      "[1,  4700] loss: 0.525\n",
      "[1,  4800] loss: 0.486\n",
      "[1,  4900] loss: 0.509\n",
      "[1,  5000] loss: 0.488\n",
      "[1,  5100] loss: 0.529\n",
      "[1,  5200] loss: 0.498\n",
      "[1,  5300] loss: 0.509\n",
      "[1,  5400] loss: 0.497\n",
      "[1,  5500] loss: 0.498\n",
      "[1,  5600] loss: 0.501\n",
      "[1,  5700] loss: 0.517\n",
      "[1,  5800] loss: 0.508\n",
      "[1,  5900] loss: 0.514\n",
      "[1,  6000] loss: 0.513\n",
      "[1,  6100] loss: 0.525\n",
      "[1,  6200] loss: 0.504\n",
      "[1,  6300] loss: 0.537\n",
      "[1,  6400] loss: 0.492\n",
      "[1,  6500] loss: 0.512\n",
      "[1,  6600] loss: 0.499\n",
      "[1,  6700] loss: 0.473\n",
      "[1,  6800] loss: 0.510\n",
      "[1,  6900] loss: 0.525\n",
      "[1,  7000] loss: 0.491\n",
      "[1,  7100] loss: 0.505\n",
      "[1,  7200] loss: 0.504\n",
      "[1,  7300] loss: 0.535\n",
      "[1,  7400] loss: 0.515\n",
      "[1,  7500] loss: 0.528\n",
      "[1,  7600] loss: 0.509\n",
      "[1,  7700] loss: 0.502\n",
      "[1,  7800] loss: 0.499\n",
      "[1,  7900] loss: 0.494\n",
      "[1,  8000] loss: 0.491\n",
      "[1,  8100] loss: 0.501\n",
      "[1,  8200] loss: 0.499\n",
      "[1,  8300] loss: 0.490\n",
      "[1,  8400] loss: 0.496\n",
      "[1,  8500] loss: 0.491\n",
      "[1,  8600] loss: 0.482\n",
      "[1,  8700] loss: 0.498\n",
      "[1,  8800] loss: 0.493\n",
      "[1,  8900] loss: 0.523\n",
      "[1,  9000] loss: 0.493\n",
      "[1,  9100] loss: 0.503\n",
      "[1,  9200] loss: 0.505\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "main函数，模型具体的过程\n",
    "\n",
    "\n",
    "'''\n",
    "def tab_printer(args):\n",
    "    \"\"\"\n",
    "    Function to print the logs in a nice tabular format.\n",
    "    :param args: Parameters used for the model.\n",
    "    \"\"\"\n",
    "    args = vars(args)\n",
    "    keys = sorted(args.keys())\n",
    "    t = Texttable()\n",
    "    t.add_rows([[\"Parameter\", \"Value\"]])\n",
    "    t.add_rows([[k.replace(\"_\", \" \").capitalize(), args[k]] for k in keys])\n",
    "    print(t.draw())\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #args = parser.parse_known_args()[0]\n",
    "    args = parameter_parsers()\n",
    "    tab_printer(args)\n",
    "    \n",
    "    #使用GPU训练，要找机器的GPU序号\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    use_cuda = False\n",
    "    if torch.cuda.is_available():\n",
    "        use_cuda = True\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    #输出一下当前是否使用到了GPU训练模型\n",
    "    print(device)\n",
    "    \n",
    "    #读取数据文件\n",
    "    dir_data = 'data/' + args.data\n",
    "    path_data = dir_data + \".pkl\"\n",
    "    data_file = open(path_data,'rb')\n",
    "    \n",
    "    #读取数据\n",
    "    history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, traindata, validdata, testdata, social_adj_lists, item_adj_lists, ratings_list = pickle.load(\n",
    "        data_file)\n",
    "    #np.array()产生数组对象\n",
    "    traindata = np.array(traindata)\n",
    "    validdata = np.array(validdata)\n",
    "    testdata = np.array(testdata)   \n",
    "    #X[:,0]取二维数组中的第一列所有行的数据，以此类推\n",
    "    train_u = traindata[:, 0]\n",
    "    train_v = traindata[:, 1]\n",
    "    train_r = traindata[:, 2]\n",
    "    train_label = traindata[:, 3]\n",
    "    \n",
    "    valid_u = validdata[:, 0]\n",
    "    valid_v = validdata[:, 1]\n",
    "    valid_r = validdata[:, 2]\n",
    "    valid_label = validdata[:, 3]\n",
    "    \n",
    "    test_u = testdata[:, 0]\n",
    "    test_v = testdata[:, 1]\n",
    "    test_r = testdata[:, 2]\n",
    "    test_label = testdata[:, 3]\n",
    "    \n",
    "    trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),\n",
    "                                              torch.FloatTensor(train_r), torch.FloatTensor(train_label))\n",
    "    validset = torch.utils.data.TensorDataset(torch.LongTensor(valid_u), torch.LongTensor(valid_v),\n",
    "                                              torch.FloatTensor(valid_r), torch.FloatTensor(valid_label))\n",
    "    testset = torch.utils.data.TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v),\n",
    "                                             torch.FloatTensor(test_r), torch.FloatTensor(test_label))\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=args.test_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=True)\n",
    "    #user,item和rating的数量\n",
    "    num_users = history_u_lists.__len__()\n",
    "    num_items = history_v_lists.__len__()\n",
    "    num_ratings = ratings_list.__len__()\n",
    "    \n",
    "    \n",
    "    #嵌入层\n",
    "    embed_dim = args.embed_dim\n",
    "    u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
    "    v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
    "    #注意在对评分进行嵌入时，需要考虑0评分，即在rating_list中没有的评分，所以要num_ratings + 1\n",
    "    r2e = nn.Embedding(num_ratings + 1, embed_dim).to(device)\n",
    "    \n",
    "    #辅助的社交图模块，生成的是更新的u2e.weight\n",
    "    model = AttentionWalkTrainer(args)\n",
    "    model.fit()\n",
    "    new_u2e = model.get_embedding()\n",
    "    \n",
    "    \n",
    "    #两个embedding的比较\n",
    "    #print(u2e.weight[0])\n",
    "    #print(new_u2e[0])\n",
    "    #print(len(u2e.weight))\n",
    "    #print(len(new_u2e))\n",
    "    \n",
    "   \n",
    "    node_agg = UV_Aggregator(v2e, r2e, u2e, new_u2e, embed_dim, r2e.num_embeddings - 1, cuda=device)\n",
    "    #print(1)\n",
    "    node_enc = UV_Encoder(u2e, v2e, embed_dim, history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, social_adj_lists, item_adj_lists, node_agg, percent=args.percent,  cuda=device)\n",
    "    #print(2)\n",
    "    #NERec model\n",
    "    nerec = NERec(node_enc, r2e).to(device)\n",
    "    \n",
    "    #optimizer:Adam,衰减率初始为0.0001\n",
    "    optimizer = torch.optim.Adam(nerec.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "    #optimizer = Ranger(nerec.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "    \n",
    "    #如果有程序断点，并且--load_from_checkpoint设置为True，则读取断点时保存的模型并加载\n",
    "    if args.load_from_checkpoint == True:\n",
    "        checkpoint = torch.load('models/' + args.data + '.pt')\n",
    "        nerec.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])    \n",
    "        \n",
    "    best_rmse = 9999.0\n",
    "    best_mae = 9999.0\n",
    "    #设置一个训练次数的参数，如果训练的目标5轮没有提升，自动停止程序\n",
    "    endure_count = 0\n",
    "\n",
    "    #把新的评价指标的评测函数放到一个_metron中，用外部的类来进行运行\n",
    "    _metron = MetronAtK(top_k=5)\n",
    "    \n",
    "    index_sum = []\n",
    "    pre_sum = 0\n",
    "    best_sum = 0\n",
    "    for epoch in range(1, args.mepochs + 1):\n",
    "\n",
    "        train(nerec, device, train_loader, optimizer, epoch)\n",
    "        #ranking的评价指标和rating不同，不是rmse 和MAE\n",
    "        #先验证，再test\n",
    "        expected_recall, expected_ndcg = test(nerec, device, valid_loader, _metron)\n",
    "        if epoch == 0:\n",
    "            pre_sum = expected_recall + expected_ndcg\n",
    "            index_sum.append(0)\n",
    "        else:\n",
    "            if expected_recall + expected_ndcg < pre_sum:\n",
    "                index_sum.append(1)\n",
    "            else:\n",
    "                pre_sum = expected_recall + expected_ndcg\n",
    "                index_sum.append(0)\n",
    "        if sum(index_sum[-10:]) == 10:\n",
    "            break\n",
    "        if epoch == 0:\n",
    "            best_sum = expected_recall + expected_ndcg\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': nerec.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'models/' + args.data + '.pt')\n",
    "        elif expected_recall + expected_ndcg > best_sum:\n",
    "            best_sum = expected_recall + expected_ndcg\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': nerec.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'models/' + args.data + '.pt')\n",
    "        #if best_recall > expected_recall:\n",
    "            #best_recall = expected_recall\n",
    "            #best_mae = mae\n",
    "            #endure_count = 0\n",
    "            #torch.save({\n",
    "            #'epoch': epoch,\n",
    "            #'model_state_dict': nerec.state_dict(),\n",
    "            #'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #}, 'models/' + args.data + '.pt')\n",
    "        #else:\n",
    "            #endure_count += 1\n",
    "        print(\"NERec Recall on valid set: %.4f, NDCG:%.4f \" % (expected_recall, expected_ndcg))\n",
    "        t_recall, t_ndcg = test(nerec, device, test_loader, _metron)\n",
    "        print('NERec Recall on test set: %.4f, NDCG:%.4f '%(t_recall, t_ndcg))\n",
    "\n",
    "    print('finished')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c00f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
