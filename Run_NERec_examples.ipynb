{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda3fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch7ten\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import\n",
    "\n",
    "导入所需要的所有包\n",
    "\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from UV_Encoders import UV_Encoder\n",
    "from UV_Aggregators import UV_Aggregator\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "from texttable import Texttable\n",
    "from param_parser import parameter_parser\n",
    "from utils import tab_printer\n",
    "from attentionwalk import AttentionWalkTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963c6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NERec模型主体\n",
    "\n",
    "'''\n",
    "\n",
    "class NERec(nn.Module):\n",
    "    \n",
    "    def __init__(self, node_enc, r2e):\n",
    "        super(NERec, self).__init__()    \n",
    "        #和GraphRec不同，由于部分item相连，使得item也有两种邻居，将user和item节点视作一类，后面在模型里对user和item不同的处理则根据uv这个变量进行分类\n",
    "        self.node_enc = node_enc\n",
    "        self.embed_dim = node_enc.embed_dim\n",
    "        #MLP多层感知器\n",
    "        #self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        #self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
    "        #self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
    "        #self.w_uv3 = nn.Linear(16, 1)\n",
    "        #self.r2e = r2e\n",
    "        #self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        #self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        #self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        #self.bn4 = nn.BatchNorm1d(16, momentum=0.5)      \n",
    "        #loss函数使用torch.nn自带的损失函数，详细介绍见https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, nodes_u, nodes_v):\n",
    "        \n",
    "        #利用uv变量区分user和item节点，False为user节点，True为item节点\n",
    "        embeds_u = self.node_enc(nodes_u, nodes_v, uv = False)\n",
    "        embeds_v = self.node_enc(nodes_v, nodes_u, uv = True)\n",
    "        \n",
    "        #向量点积\n",
    "        scores = torch.mm(embeds_u, embeds_v.t()).diagonal()\n",
    "        return scores\n",
    "\n",
    "        #MLP多层感知器\n",
    "        #x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
    "        #x_u = F.dropout(x_u, training=self.training)\n",
    "        #x_u = self.w_ur2(x_u)\n",
    "        #x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
    "        #x_v = F.dropout(x_v, training=self.training)\n",
    "        #x_v = self.w_vr2(x_v)\n",
    "\n",
    "        #x_uv = torch.cat((x_u, x_v), 1)\n",
    "        #x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = F.relu(self.bn4(self.w_uv2(x)))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #scores = self.w_uv3(x)\n",
    "\n",
    "    def loss(self, nodes_u, nodes_v, labels_list):\n",
    "        scores = self.forward(nodes_u, nodes_v)\n",
    "        return self.criterion(scores, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d33ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "训练模型以及对验证集和测试集测试计算指标\n",
    "\n",
    "optimizer选择：Adam，学习率初始为0.001，衰减率初始为00001\n",
    "使用方法：\n",
    "torch.optim.Adam(NERec.parameters, lr, weight_decay)\n",
    "torch.optim中文文档：\n",
    "https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-optim/\n",
    "\n",
    "'''\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, best_rmse, best_mae):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        batch_nodes_u, batch_nodes_v, labels_list = data\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f, The best rmse/mae: %.6f / %.6f' % (\n",
    "                epoch, i, running_loss / 100, best_rmse, best_mae))\n",
    "            running_loss = 0.0\n",
    "    return 0\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    tmp_pred = []\n",
    "    target = []\n",
    "    with torch.no_grad():\n",
    "        for test_u, test_v, tmp_target in test_loader:\n",
    "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
    "            val_output = model.forward(test_u, test_v)\n",
    "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
    "            target.append(list(tmp_target.data.cpu().numpy()))\n",
    "    tmp_pred = np.array(sum(tmp_pred, []))\n",
    "    target = np.array(sum(target, []))\n",
    "    expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
    "    mae = mean_absolute_error(tmp_pred, target)\n",
    "    return expected_rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493e241",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------------+\n",
      "|      Batch size      |            16             |\n",
      "+======================+===========================+\n",
      "| Beta                 | 0.500                     |\n",
      "+----------------------+---------------------------+\n",
      "| Data                 | ciao2                     |\n",
      "+----------------------+---------------------------+\n",
      "| Device               | cuda                      |\n",
      "+----------------------+---------------------------+\n",
      "| Dimensions           | 16                        |\n",
      "+----------------------+---------------------------+\n",
      "| Edge path            | ./input/ciao_edges_16.csv |\n",
      "+----------------------+---------------------------+\n",
      "| Embed dim            | 16                        |\n",
      "+----------------------+---------------------------+\n",
      "| Epochs               | 3                         |\n",
      "+----------------------+---------------------------+\n",
      "| Gamma                | 0.500                     |\n",
      "+----------------------+---------------------------+\n",
      "| Learning rate        | 0.010                     |\n",
      "+----------------------+---------------------------+\n",
      "| Load from checkpoint | 0                         |\n",
      "+----------------------+---------------------------+\n",
      "| Lr                   | 0.001                     |\n",
      "+----------------------+---------------------------+\n",
      "| Num of walks         | 80                        |\n",
      "+----------------------+---------------------------+\n",
      "| Percent              | 0.200                     |\n",
      "+----------------------+---------------------------+\n",
      "| Test batch size      | 1000                      |\n",
      "+----------------------+---------------------------+\n",
      "| Weight decay         | 0.000                     |\n",
      "+----------------------+---------------------------+\n",
      "| Window size          | 5                         |\n",
      "+----------------------+---------------------------+\n",
      "cuda\n",
      "\n",
      "Target matrix creation started.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adjacency matrix powers: 100%|██████████| 4/4 [00:09<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Social Graph Mmodel.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention Walk (Loss=36.7533):  67%|██████▋   | 2/3 [00:02<00:01,  1.47s/it]"
     ]
    }
   ],
   "source": [
    "'''\n",
    "main函数，模型具体的过程\n",
    "\n",
    "\n",
    "'''\n",
    "def tab_printer(args):\n",
    "    \"\"\"\n",
    "    Function to print the logs in a nice tabular format.\n",
    "    :param args: Parameters used for the model.\n",
    "    \"\"\"\n",
    "    args = vars(args)\n",
    "    keys = sorted(args.keys())\n",
    "    t = Texttable()\n",
    "    t.add_rows([[\"Parameter\", \"Value\"]])\n",
    "    t.add_rows([[k.replace(\"_\", \" \").capitalize(), args[k]] for k in keys])\n",
    "    print(t.draw())\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #args = parser.parse_known_args()[0]\n",
    "    args = parameter_parser()\n",
    "    tab_printer(args)\n",
    "    \n",
    "    #使用GPU训练，要找机器的GPU序号\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    use_cuda = False\n",
    "    if torch.cuda.is_available():\n",
    "        use_cuda = True\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    #输出一下当前是否使用到了GPU训练模型\n",
    "    print(device)\n",
    "    \n",
    "    #读取数据文件\n",
    "    dir_data = 'data/' + args.data\n",
    "    path_data = dir_data + \".pkl\"\n",
    "    data_file = open(path_data,'rb')\n",
    "    \n",
    "    #读取数据\n",
    "    history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, traindata, validdata, testdata, social_adj_lists, item_adj_lists, ratings_list = pickle.load(\n",
    "        data_file)\n",
    "    #np.array()产生数组对象\n",
    "    traindata = np.array(traindata)\n",
    "    validdata = np.array(validdata)\n",
    "    testdata = np.array(testdata)   \n",
    "    #X[:,0]取二维数组中的第一列所有行的数据，以此类推\n",
    "    train_u = traindata[:, 0]\n",
    "    train_v = traindata[:, 1]\n",
    "    train_r = traindata[:, 2]\n",
    "    valid_u = validdata[:, 0]\n",
    "    valid_v = validdata[:, 1]\n",
    "    valid_r = validdata[:, 2]\n",
    "    test_u = testdata[:, 0]\n",
    "    test_v = testdata[:, 1]\n",
    "    test_r = testdata[:, 2]\n",
    "    trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),\n",
    "                                              torch.FloatTensor(train_r))\n",
    "    validset = torch.utils.data.TensorDataset(torch.LongTensor(valid_u), torch.LongTensor(valid_v),\n",
    "                                              torch.FloatTensor(valid_r))\n",
    "    testset = torch.utils.data.TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v),\n",
    "                                             torch.FloatTensor(test_r))\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=args.test_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=True)\n",
    "    #user,item和rating的数量\n",
    "    num_users = history_u_lists.__len__()\n",
    "    num_items = history_v_lists.__len__()\n",
    "    num_ratings = ratings_list.__len__()\n",
    "    \n",
    "    \n",
    "    #嵌入层\n",
    "    embed_dim = args.embed_dim\n",
    "    u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
    "    v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
    "    #注意在对评分进行嵌入时，需要考虑0评分，即在rating_list中没有的评分，所以要num_ratings + 1\n",
    "    r2e = nn.Embedding(num_ratings + 1, embed_dim).to(device)\n",
    "    \n",
    "    #辅助的社交图模块，生成的是更新的u2e.weight\n",
    "    model = AttentionWalkTrainer(args)\n",
    "    model.fit()\n",
    "    new_u2e = model.get_embedding()\n",
    "    \n",
    "    \n",
    "    #两个embedding的比较\n",
    "    #print(u2e.weight[0])\n",
    "    #print(new_u2e[0])\n",
    "    #print(len(u2e.weight))\n",
    "    #print(len(new_u2e))\n",
    "    \n",
    "   \n",
    "    node_agg = UV_Aggregator(v2e, r2e, u2e, new_u2e, embed_dim, r2e.num_embeddings - 1, cuda=device)\n",
    "    #print(1)\n",
    "    node_enc = UV_Encoder(u2e, v2e, embed_dim, history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, social_adj_lists, item_adj_lists, node_agg, percent=args.percent,  cuda=device)\n",
    "    #print(2)\n",
    "    #NERec model\n",
    "    nerec = NERec(node_enc, r2e).to(device)\n",
    "    \n",
    "    #optimizer:Adam,衰减率初始为0.0001\n",
    "    optimizer = torch.optim.Adam(nerec.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "    #optimizer = Ranger(nerec.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "    \n",
    "    #如果有程序断点，并且--load_from_checkpoint设置为True，则读取断点时保存的模型并加载\n",
    "    if args.load_from_checkpoint == True:\n",
    "        checkpoint = torch.load('models/' + args.data + '.pt')\n",
    "        nerec.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])    \n",
    "        \n",
    "    best_rmse = 9999.0\n",
    "    best_mae = 9999.0\n",
    "    #设置一个训练次数的参数，如果训练的目标5轮没有提升，自动停止程序\n",
    "    endure_count = 0\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "        train(nerec, device, train_loader, optimizer, epoch, best_rmse, best_mae)\n",
    "        expected_rmse, mae = test(nerec, device, valid_loader)\n",
    "        if best_rmse > expected_rmse:\n",
    "            best_rmse = expected_rmse\n",
    "            best_mae = mae\n",
    "            endure_count = 0\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': nerec.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'models/' + args.data + '.pt')\n",
    "        else:\n",
    "            endure_count += 1\n",
    "        print(\"NERec rmse on valid set: %.4f, mae:%.4f \" % (expected_rmse, mae))\n",
    "        rmse, mae = test(nerec, device, test_loader)\n",
    "        print('NERec rmse on test set: %.4f, mae:%.4f '%(rmse, mae))\n",
    "\n",
    "        if endure_count > 5:\n",
    "            break\n",
    "    print('finished')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c00f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
